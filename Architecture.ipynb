{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Building the Vesuvius 3D Surface Detector\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1.  **3D Volumetric Data**: Using `Conv3d` layers instead of `Conv2d`.\n",
                "2.  **Low Memory Constraints (8GB VRAM)**: Using `GroupNorm` (stable at batch size 1) and Gradient Checkpointing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.utils.checkpoint as checkpoint\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. The Building Block: Residual Layer\n",
                "\n",
                "A standard U-Net uses simple convolution blocks. We upgrade this to **Residual Blocks** (ResNet style) which allow gradients to flow better during training, enabling deeper networks.\n",
                "\n",
                "### Why GroupNorm?\n",
                "*   **BatchNorm**: Normalizes across the Batch dimension. Requires large batches (e.g., 16+) to be accurate. We can only fit Batch Size = 1.\n",
                "*   **GroupNorm**: Normalizes across the Channel dimension. Works perfectly even with Batch Size = 1.\n",
                "\n",
                "We create a block that does: `Conv3D -> GroupNorm -> LeakyReLU -> Conv3D -> GroupNorm`. And adds the original input (`x`) back at the end."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ResidualBlock(nn.Module):\n",
                "    def __init__(self, in_channels, out_channels):\n",
                "        super().__init__()\n",
                "        # 1st Convolution\n",
                "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
                "        self.gn1 = nn.GroupNorm(8, out_channels) # GroupNorm is key for small batches\n",
                "        self.act1 = nn.LeakyReLU(inplace=True)\n",
                "        \n",
                "        # 2nd Convolution\n",
                "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
                "        self.gn2 = nn.GroupNorm(8, out_channels)\n",
                "        self.act2 = nn.LeakyReLU(inplace=True)\n",
                "\n",
                "        # Shortcut connection (to match dimensions if in != out)\n",
                "        if in_channels != out_channels:\n",
                "            self.shortcut = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
                "        else:\n",
                "            self.shortcut = nn.Identity()\n",
                "\n",
                "    def forward(self, x):\n",
                "        original = x\n",
                "        \n",
                "        # Pass through layers\n",
                "        x = self.conv1(x)\n",
                "        x = self.gn1(x)\n",
                "        x = self.act1(x)\n",
                "        x = self.conv2(x)\n",
                "        x = self.gn2(x)\n",
                "        \n",
                "        # Add residual (the \"Res\" in ResNet)\n",
                "        residual = self.shortcut(original)\n",
                "        x += residual\n",
                "        return self.act2(x)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. The Architecture: U-Net Encoder & Decoder\n",
                "\n",
                "Now we assemble the blocks.\n",
                "\n",
                "*   **Encoder (Down)**: Reduces spatial size (128->64->32), increases depth (Features 16->32->64). Captures context.\n",
                "*   **Decoder (Up)**: Increases spatial size (32->64->128), decreases depth. Refines details.\n",
                "*   **Skip Connections**: We modify the Forward pass to concatenate Encoder features with Decoder features. This preserves fine-grained details.\n",
                "*   **Gradient Checkpointing**: This is a memory trick! Instead of storing ALL activations in memory for backprop, we re-compute them on the fly. This makes training **slower (30%)** but uses **much less VRAM (50%)**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class UNet3D(nn.Module):\n",
                "    def __init__(self, in_channels=1, out_channels=1, init_features=16):\n",
                "        super().__init__()\n",
                "        \n",
                "        # --- ENCODER ---\n",
                "        self.enc1 = ResidualBlock(in_channels, init_features)\n",
                "        self.pool1 = nn.MaxPool3d(2, 2)\n",
                "        \n",
                "        self.enc2 = ResidualBlock(init_features, init_features * 2)\n",
                "        self.pool2 = nn.MaxPool3d(2, 2)\n",
                "        \n",
                "        self.enc3 = ResidualBlock(init_features * 2, init_features * 4)\n",
                "        self.pool3 = nn.MaxPool3d(2, 2)\n",
                "        \n",
                "        # --- BOTTLENECK ---\n",
                "        self.bottleneck = ResidualBlock(init_features * 4, init_features * 8)\n",
                "        \n",
                "        # --- DECODER ---\n",
                "        # Uses Transpose Conv to upsample\n",
                "        self.up3 = nn.ConvTranspose3d(init_features * 8, init_features * 4, kernel_size=2, stride=2)\n",
                "        self.dec3 = ResidualBlock(init_features * 8, init_features * 4)\n",
                "        \n",
                "        self.up2 = nn.ConvTranspose3d(init_features * 4, init_features * 2, kernel_size=2, stride=2)\n",
                "        self.dec2 = ResidualBlock(init_features * 4, init_features * 2)\n",
                "        \n",
                "        self.up1 = nn.ConvTranspose3d(init_features * 2, init_features, kernel_size=2, stride=2)\n",
                "        self.dec1 = ResidualBlock(init_features * 2, init_features)\n",
                "        \n",
                "        # --- FINAL --- \n",
                "        self.final = nn.Conv3d(init_features, out_channels, kernel_size=1)\n",
                "        self.activation = nn.Sigmoid() # Output 0-1 probability\n",
                "\n",
                "    def forward(self, x):\n",
                "        # Encoder L1\n",
                "        e1 = self.enc1(x)\n",
                "        p1 = self.pool1(e1)\n",
                "        \n",
                "        # Encoder L2 (We use checkpointing here to save RAM)\n",
                "        if self.training:\n",
                "            e2 = checkpoint.checkpoint(self.run_enc2, p1, use_reentrant=False)\n",
                "        else:\n",
                "            e2 = self.enc2(p1)\n",
                "        p2 = self.pool2(e2)\n",
                "        \n",
                "        # Encoder L3 (Checkpoint here too)\n",
                "        if self.training:\n",
                "            e3 = checkpoint.checkpoint(self.run_enc3, p2, use_reentrant=False)\n",
                "        else:\n",
                "            e3 = self.enc3(p2)\n",
                "        p3 = self.pool3(e3)\n",
                "        \n",
                "        # Bottleneck\n",
                "        b = self.bottleneck(p3)\n",
                "        \n",
                "        # Decoder L3\n",
                "        u3 = self.up3(b)\n",
                "        # Skip Connection: Concatenate u3 with e3\n",
                "        d3 = self.dec3(torch.cat((u3, e3), dim=1))\n",
                "        \n",
                "        # Decoder L2\n",
                "        u2 = self.up2(d3)\n",
                "        d2 = self.dec2(torch.cat((u2, e2), dim=1))\n",
                "        \n",
                "        # Decoder L1\n",
                "        u1 = self.up1(d2)\n",
                "        d1 = self.dec1(torch.cat((u1, e1), dim=1))\n",
                "        \n",
                "        return self.activation(self.final(d1))\n",
                "    \n",
                "    # Helpers for checkpointing\n",
                "    def run_enc2(self, x): return self.enc2(x)\n",
                "    def run_enc3(self, x): return self.enc3(x)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Sanity Check\n",
                "\n",
                "Let's put a dummy 3D volume into the model and see if it outputs the correct shape.\n",
                "\n",
                "Input Shape: `(Batch=1, Channel=1, Depth=32, Height=128, Width=128)`\n",
                "Expected Output: `(1, 1, 32, 128, 128)`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Instantiate Model\n",
                "model = UNet3D(init_features=16).to(device)\n",
                "print(\"Model created successfully on GPU.\")\n",
                "\n",
                "# Create Dummy Input\n",
                "dummy_input = torch.randn(1, 1, 32, 128, 128).to(device)\n",
                "print(f\"Input Shape: {dummy_input.shape}\")\n",
                "\n",
                "# Forward Pass\n",
                "with torch.no_grad():\n",
                "    output = model(dummy_input)\n",
                "    \n",
                "print(f\"Output Shape: {output.shape}\")\n",
                "\n",
                "if output.shape == dummy_input.shape:\n",
                "    print(\"✅ Architecture verification passed! Output matches Input dimensions.\")\n",
                "else:\n",
                "    print(\"❌ Mismatch! Something is wrong with padding or strides.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
